{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-04-07T13:18:36.485109Z","iopub.execute_input":"2022-04-07T13:18:36.485582Z","iopub.status.idle":"2022-04-07T13:18:36.759048Z","shell.execute_reply.started":"2022-04-07T13:18:36.485533Z","shell.execute_reply":"2022-04-07T13:18:36.758154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport cv2\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:18:39.841203Z","iopub.execute_input":"2022-04-07T13:18:39.842434Z","iopub.status.idle":"2022-04-07T13:18:47.396527Z","shell.execute_reply.started":"2022-04-07T13:18:39.842335Z","shell.execute_reply":"2022-04-07T13:18:47.395341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\nmovenet = model.signatures['serving_default']","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:18:47.398234Z","iopub.execute_input":"2022-04-07T13:18:47.398594Z","iopub.status.idle":"2022-04-07T13:19:02.316904Z","shell.execute_reply.started":"2022-04-07T13:18:47.39855Z","shell.execute_reply":"2022-04-07T13:19:02.315971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Autoencoder = tf.keras.models.load_model('../input/model-final/autoencoder-model_justCSA5.h5')\nAutoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:19:02.318512Z","iopub.execute_input":"2022-04-07T13:19:02.319198Z","iopub.status.idle":"2022-04-07T13:19:02.636628Z","shell.execute_reply.started":"2022-04-07T13:19:02.319134Z","shell.execute_reply":"2022-04-07T13:19:02.635531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(Autoencoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:19:02.637785Z","iopub.execute_input":"2022-04-07T13:19:02.638016Z","iopub.status.idle":"2022-04-07T13:19:03.550032Z","shell.execute_reply.started":"2022-04-07T13:19:02.637987Z","shell.execute_reply":"2022-04-07T13:19:03.549189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport glob\n\npath = '../input/test-set/Test_normal_data_update'\npath_list = []\nevl_list =[]\nkeypoints_with_scores_train = []\nfor k in glob.glob(os.path.join(path,'*.mp4')):\n    frame_list = []\n    print(k)\n    path_list.append(k)\n    cap = cv2.VideoCapture(k)\n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            print(\"Can't receive frame (stream end?). Exiting ...\")\n            break\n    \n    # Resize image\n        img = frame.copy()\n        img = img[680:2000, 400:680]\n        #cv2.imwrite('/kaggle',img)\n        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 224,224)\n        input_img = tf.cast(img, dtype=tf.int32)\n    \n       \n    # Detection section\n        results = movenet(input_img)\n        keypoints_with_scores = results['output_0'].numpy()[:,0,:51].reshape(51)\n        frame_list.append(keypoints_with_scores)\n        frame_list_np = np.asarray(frame_list)\n    keypoints_with_scores_train.append(frame_list_np[30:120,:])\n    keypoints_with_scores_train_np = np.asarray(keypoints_with_scores_train)\n    print(keypoints_with_scores_train_np.shape)\n    evl = Autoencoder.evaluate(keypoints_with_scores_train_np,keypoints_with_scores_train_np)\n    evl_list.append(evl)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:19:06.754517Z","iopub.execute_input":"2022-04-07T13:19:06.755055Z","iopub.status.idle":"2022-04-07T13:22:47.588912Z","shell.execute_reply.started":"2022-04-07T13:19:06.754999Z","shell.execute_reply":"2022-04-07T13:22:47.587931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=pd.DataFrame(evl_list,columns=['loss','mae'])\ndf1['file'] = path_list\n#df1[df1['loss']>0.0130].count()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:22:47.590794Z","iopub.execute_input":"2022-04-07T13:22:47.591018Z","iopub.status.idle":"2022-04-07T13:22:47.606494Z","shell.execute_reply.started":"2022-04-07T13:22:47.59099Z","shell.execute_reply":"2022-04-07T13:22:47.605749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.DataFrame(evl_list,columns=['loss'])\ndf2['file'] = path_list\ndf2[df2['loss']>0.0130].count()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:22:47.607971Z","iopub.execute_input":"2022-04-07T13:22:47.608796Z","iopub.status.idle":"2022-04-07T13:22:47.860941Z","shell.execute_reply.started":"2022-04-07T13:22:47.608746Z","shell.execute_reply":"2022-04-07T13:22:47.859628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.to_csv(\"normal_csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T15:34:24.58579Z","iopub.status.idle":"2022-04-04T15:34:24.58613Z","shell.execute_reply.started":"2022-04-04T15:34:24.585926Z","shell.execute_reply":"2022-04-04T15:34:24.585942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.to_csv(\"N_modeljustCSAfinal.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-07T13:22:47.861973Z","iopub.status.idle":"2022-04-07T13:22:47.862311Z","shell.execute_reply.started":"2022-04-07T13:22:47.862153Z","shell.execute_reply":"2022-04-07T13:22:47.862169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport glob\n\npath = '../input/csa-normal-walk-updated/normal walk CSA'\npath_list = []\nevl_list =[]\nfor k in glob.glob(os.path.join(path,'*.mp4')):\n    frame_list = []\n    print(k)\n    path_list.append(k)\n    cap = cv2.VideoCapture(k)\n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            print(\"Can't receive frame (stream end?). Exiting ...\")\n            break\n    \n    # Resize image\n        img = frame.copy()\n        img = img[680:2000, 400:680]\n        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 224,224)\n        input_img = tf.cast(img, dtype=tf.int32)\n    \n       \n    # Detection section\n        results = movenet(input_img)\n        keypoints_with_scores = results['output_0'].numpy()[:,0,:51].reshape(51)\n        frame_list.append(keypoints_with_scores)\n        frame_list_np = np.asarray(frame_list)\n    keypoints_with_scores_train = []\n    for x in range(90,len(frame_list_np)):\n        keypoints_with_scores_train.append(frame_list_np[x-90:x,:])\n    keypoints_with_scores_train = np.asarray(keypoints_with_scores_train)\n    print(keypoints_with_scores_train.shape)\n    evl = Autoencoder.evaluate(keypoints_with_scores_train,keypoints_with_scores_train)\n    evl_list.append(evl)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:38:17.797231Z","iopub.execute_input":"2022-03-31T14:38:17.797683Z","iopub.status.idle":"2022-03-31T14:58:45.366392Z","shell.execute_reply.started":"2022-03-31T14:38:17.797638Z","shell.execute_reply":"2022-03-31T14:58:45.365258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=pd.DataFrame(evl_list,columns=['mse','mae','cosin'])\ndf3['file'] = path_list\ndf3","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:58:45.367989Z","iopub.execute_input":"2022-03-31T14:58:45.36842Z","iopub.status.idle":"2022-03-31T14:58:45.392342Z","shell.execute_reply.started":"2022-03-31T14:58:45.368381Z","shell.execute_reply":"2022-03-31T14:58:45.391499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.to_csv(\"normal_video_withmodel4.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:58:45.394421Z","iopub.execute_input":"2022-03-31T14:58:45.394958Z","iopub.status.idle":"2022-03-31T14:58:45.402247Z","shell.execute_reply.started":"2022-03-31T14:58:45.394919Z","shell.execute_reply":"2022-03-31T14:58:45.40143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport glob\n\npath = '../input/highly-drunk/highly drunk walk'\npath_list = []\nevl_list =[]\nfor k in glob.glob(os.path.join(path,'*.mp4')):\n    frame_list = []\n    print(k)\n    path_list.append(k)\n    cap = cv2.VideoCapture(k)\n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            print(\"Can't receive frame (stream end?). Exiting ...\")\n            break\n    \n    # Resize image\n        img = frame.copy()\n        img = img[680:2000, 400:680]\n        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 224,224)\n        input_img = tf.cast(img, dtype=tf.int32)\n    \n       \n    # Detection section\n        results = movenet(input_img)\n        keypoints_with_scores = results['output_0'].numpy()[:,0,:51].reshape(51)\n        frame_list.append(keypoints_with_scores)\n        frame_list_np = np.asarray(frame_list)\n    keypoints_with_scores_train = []\n    for x in range(90,len(frame_list_np)):\n        keypoints_with_scores_train.append(frame_list_np[x-90:x,:])\n    keypoints_with_scores_train = np.asarray(keypoints_with_scores_train)\n    print(keypoints_with_scores_train.shape)\n    evl = Autoencoder.evaluate(keypoints_with_scores_train,keypoints_with_scores_train)\n    evl_list.append(evl)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:03:13.744823Z","iopub.execute_input":"2022-03-31T15:03:13.74526Z","iopub.status.idle":"2022-03-31T15:05:51.622367Z","shell.execute_reply.started":"2022-03-31T15:03:13.745203Z","shell.execute_reply":"2022-03-31T15:05:51.621249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4=pd.DataFrame(evl_list,columns=['mse','mae','cosin'])\ndf4['file'] = path_list\ndf4","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:06:02.496743Z","iopub.execute_input":"2022-03-31T15:06:02.497035Z","iopub.status.idle":"2022-03-31T15:06:02.512313Z","shell.execute_reply.started":"2022-03-31T15:06:02.497006Z","shell.execute_reply":"2022-03-31T15:06:02.511628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.to_csv(\"normal_video_csv.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-31T01:28:15.54358Z","iopub.execute_input":"2022-03-31T01:28:15.543895Z","iopub.status.idle":"2022-03-31T01:28:15.561048Z","shell.execute_reply.started":"2022-03-31T01:28:15.543851Z","shell.execute_reply":"2022-03-31T01:28:15.559997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.to_csv(\"highly+drunk_video_withmodel4.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:06:07.676866Z","iopub.execute_input":"2022-03-31T15:06:07.677385Z","iopub.status.idle":"2022-03-31T15:06:07.682684Z","shell.execute_reply.started":"2022-03-31T15:06:07.677333Z","shell.execute_reply":"2022-03-31T15:06:07.682005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}