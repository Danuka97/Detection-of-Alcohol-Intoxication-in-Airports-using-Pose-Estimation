{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-04-07T12:11:02.705169Z","iopub.execute_input":"2022-04-07T12:11:02.705534Z","iopub.status.idle":"2022-04-07T12:11:02.780226Z","shell.execute_reply.started":"2022-04-07T12:11:02.705453Z","shell.execute_reply":"2022-04-07T12:11:02.779498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport cv2\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-04-07T12:11:17.612436Z","iopub.execute_input":"2022-04-07T12:11:17.612716Z","iopub.status.idle":"2022-04-07T12:11:23.555649Z","shell.execute_reply.started":"2022-04-07T12:11:17.612685Z","shell.execute_reply":"2022-04-07T12:11:23.554885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\nmovenet = model.signatures['serving_default']","metadata":{"execution":{"iopub.status.busy":"2022-04-07T12:11:46.242712Z","iopub.execute_input":"2022-04-07T12:11:46.243138Z","iopub.status.idle":"2022-04-07T12:12:05.82216Z","shell.execute_reply.started":"2022-04-07T12:11:46.2431Z","shell.execute_reply":"2022-04-07T12:12:05.82143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/choke-point/Choke Point Dataset/P2L_S2_C2.1'\nkeypoint_data1 = []\nkeypoint_data2 = []\nkeypoint_data3 = []\nkeypoint_data4 = []\nkeypoint_data5 = []\nkeypoint_data6 = []\nfor k in glob.glob(os.path.join(path,'*jpg')):\n    img = cv2.imread(k)\n    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 224,224)\n    input_img = tf.cast(img, dtype=tf.int32)\n    results = movenet(input_img)\n    keypoints_with_scores_1 = results['output_0'].numpy()[:,0,:51].reshape(51)\n    keypoint_data1.append(keypoints_with_scores_1)\n    keypoints_with_scores_1 = np.asarray( keypoint_data1)\n    keypoints_with_scores_2 = results['output_0'].numpy()[:,1,:51].reshape(51)\n    keypoint_data2.append(keypoints_with_scores_2)\n    keypoints_with_scores_2 = np.asarray( keypoint_data2)\n    keypoints_with_scores_3 = results['output_0'].numpy()[:,2,:51].reshape(51)\n    keypoint_data3.append(keypoints_with_scores_3)\n    keypoints_with_scores_3 = np.asarray( keypoint_data3)\n    keypoints_with_scores_4 = results['output_0'].numpy()[:,3,:51].reshape(51)\n    keypoint_data4.append(keypoints_with_scores_4)\n    keypoints_with_scores_4 = np.asarray( keypoint_data4)\n    keypoints_with_scores_5 = results['output_0'].numpy()[:,4,:51].reshape(51)\n    keypoint_data5.append(keypoints_with_scores_5)\n    keypoints_with_scores_5 = np.asarray(keypoint_data5)\n    keypoints_with_scores_6 = results['output_0'].numpy()[:,5,:51].reshape(51)\n    keypoint_data6.append(keypoints_with_scores_6)\n    keypoints_with_scores_6 = np.asarray(keypoint_data6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport glob\n\npath = '../input/csa-train-set/OneDrive_1_05-04-2022'\ndata_set = []\nframe_list = []\nkeypoints_with_scores_train = []\nfor k in glob.glob(os.path.join(path,'*mp4')):\n    #frame_list = []\n    cap = cv2.VideoCapture(k)\n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            print(\"Can't receive frame (stream end?). Exiting ...\")\n            break\n    \n    # Resize image\n        img = frame.copy()\n        img = img[680:2000, 400:680]\n        #print(img.dtype)\n        #input_img = tf.cast(img, dtype=tf.int32)\n        #img = np.array(img)\n        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 224,224)\n        input_img = tf.cast(img, dtype=tf.int32)\n        \n       \n    # Detection section\n        results = movenet(input_img)\n        keypoints_with_scores_1 = results['output_0'].numpy()[:,0,:51].reshape(51)\n        frame_list.append(keypoints_with_scores_1)\n        keypoints_with_scores_1 = np.asarray(frame_list)\n    #keypoints_with_scores_train = []\n    keypoints_with_scores_train.append(keypoints_with_scores_1[30:120,:])\n    keypoints_with_scores_train_np = np.asarray(keypoints_with_scores_train)\n    print(keypoints_with_scores_1.shape)\n    print(keypoints_with_scores_train_np.shape)\n    \n    #keypoints_with_scores_train.append(keypoints_with_scores_1[30:120,:])\n    #keypoints_with_scores_train = []\n    #for x in range(90,len(keypoints_with_scores_1)):\n        #keypoints_with_scores_train.append(keypoints_with_scores_1[x-90:x,:])\n    #keypoints_with_scores_train_np = np.asarray(keypoints_with_scores_train)\n        #print(keypoints_with_scores_train_np.shape)\n    #data_set.append(keypoints_with_scores_train)\n    #data_set1 = np.asarray(data_set)\n    #print(keypoints_with_scores_train_np.shape)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-07T12:12:50.587526Z","iopub.execute_input":"2022-04-07T12:12:50.588387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport keras as k\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.LSTM(16, activation='relu', input_shape=(90,51), return_sequences=False))\nmodel.add(RepeatVector(90))\nmodel.add(LSTM(8, activation='relu', return_sequences=True))\nmodel.add(TimeDistributed(Dense(51)))\nmodel.compile(optimizer='adam', loss=Autoencoder_loss,metrics=['mae',tf.keras.metrics.CosineSimilarity(axis=1)])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:26:21.801875Z","iopub.execute_input":"2022-04-06T14:26:21.802148Z","iopub.status.idle":"2022-04-06T14:26:22.074457Z","shell.execute_reply.started":"2022-04-06T14:26:21.80212Z","shell.execute_reply":"2022-04-06T14:26:22.073489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks =[tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=3),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,\n                              patience=2, min_lr=0.0001)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = keypoints_with_scores_train_np[0:74,:,:]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:26:29.755085Z","iopub.execute_input":"2022-04-06T14:26:29.755351Z","iopub.status.idle":"2022-04-06T14:26:29.763216Z","shell.execute_reply.started":"2022-04-06T14:26:29.755316Z","shell.execute_reply":"2022-04-06T14:26:29.762551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = keypoints_with_scores_train_np[74:85,:,:]\ntest.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:26:31.928794Z","iopub.execute_input":"2022-04-06T14:26:31.929079Z","iopub.status.idle":"2022-04-06T14:26:31.935108Z","shell.execute_reply.started":"2022-04-06T14:26:31.929036Z","shell.execute_reply":"2022-04-06T14:26:31.934269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train,train,validation_data=(test,test),epochs=100,callbacks=callbacks,batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:45:57.649949Z","iopub.execute_input":"2022-04-06T14:45:57.650606Z","iopub.status.idle":"2022-04-06T14:45:57.860844Z","shell.execute_reply.started":"2022-04-06T14:45:57.650567Z","shell.execute_reply":"2022-04-06T14:45:57.859559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/autoencoder-model_justCSA5.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-06T00:39:42.949842Z","iopub.execute_input":"2022-04-06T00:39:42.950764Z","iopub.status.idle":"2022-04-06T00:39:42.989085Z","shell.execute_reply.started":"2022-04-06T00:39:42.950701Z","shell.execute_reply":"2022-04-06T00:39:42.988202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:37:16.934139Z","iopub.execute_input":"2022-04-06T14:37:16.934868Z","iopub.status.idle":"2022-04-06T14:37:17.117674Z","shell.execute_reply.started":"2022-04-06T14:37:16.93483Z","shell.execute_reply":"2022-04-06T14:37:17.116923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['cosine_similarity'])\nplt.plot(history.history['val_cosine_similarity'])\nplt.title('Model Cosine Similarity')\nplt.ylabel('Cosine Similarity')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:39:34.595902Z","iopub.execute_input":"2022-04-06T14:39:34.596188Z","iopub.status.idle":"2022-04-06T14:39:34.798578Z","shell.execute_reply.started":"2022-04-06T14:39:34.596156Z","shell.execute_reply":"2022-04-06T14:39:34.7979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keypoints_with_scores_train = []\nfor x in range(150,len(keypoints_with_scores_1)):\n               keypoints_with_scores_train.append(keypoints_with_scores_1[x-90:x,:])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:21:49.159143Z","iopub.execute_input":"2022-03-23T11:21:49.162227Z","iopub.status.idle":"2022-03-23T11:21:49.177236Z","shell.execute_reply.started":"2022-03-23T11:21:49.162104Z","shell.execute_reply":"2022-03-23T11:21:49.175959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keypoints_with_scores_train = np.asarray(keypoints_with_scores_train)\nkeypoints_with_scores_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:21:49.185138Z","iopub.execute_input":"2022-03-23T11:21:49.186384Z","iopub.status.idle":"2022-03-23T11:21:49.22968Z","shell.execute_reply.started":"2022-03-23T11:21:49.186334Z","shell.execute_reply":"2022-03-23T11:21:49.228847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:56:02.000527Z","iopub.execute_input":"2022-03-16T17:56:02.000808Z","iopub.status.idle":"2022-03-16T17:56:02.439137Z","shell.execute_reply.started":"2022-03-16T17:56:02.000772Z","shell.execute_reply":"2022-03-16T17:56:02.437157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Autoencoder_loss(x,x_hat):\n    a,b,d = x.shape\n    e,d,g = x_hat.shape\n    x_hat = tf.reshape(x_hat,[e,90,17,3])\n    x_hat = tf.cast(x_hat,tf.float32)\n    print(x_hat.dtype)\n    x = tf.reshape(x,[a,90,17,3])\n    x = tf.cast(x,tf.float32)\n    print(x.dtype)\n    y_diff= K.square(x[:,:,:,1] - x_hat[:,:,:,1])\n    x_diff = K.square(x[:,:,:,0] - x_hat[:,:,:,0])\n    print(y_diff.dtype)\n    print(x_diff.dtype)\n    total_diff = y_diff+x_diff\n    print(\"differnce\",total_diff.shape)\n    cof = x[:,:,:,2]\n    product_list = []\n    for l in range(len(cof[1,1,:])):\n        total_diff = tf.transpose(total_diff)\n        total_diff_che = total_diff[l,:,:]\n        cof_che = cof[:,:,l]\n        loss = K.dot(cof_che,total_diff_che)\n        print(\"trans_differnce\",loss.shape)\n        loss = tf.linalg.diag_part(loss)\n        loss = K.sum(loss)\n        product_list.append(loss)\n    print(\"coff\",cof.shape)\n    #loss = tf.tensordot(cof,total_diff,0)\n    print(loss.shape)\n    loss = no.array(product_list)\n    loss = tf.linalg.diag_part(loss)\n    print(loss.shape)\n    loss = K.sum(loss)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:45:51.573368Z","iopub.execute_input":"2022-04-06T14:45:51.573823Z","iopub.status.idle":"2022-04-06T14:45:51.585818Z","shell.execute_reply.started":"2022-04-06T14:45:51.573788Z","shell.execute_reply":"2022-04-06T14:45:51.585131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/autoencoder-model.pb')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:56:02.45847Z","iopub.status.idle":"2022-03-16T17:56:02.458932Z","shell.execute_reply.started":"2022-03-16T17:56:02.458691Z","shell.execute_reply":"2022-03-16T17:56:02.458716Z"},"trusted":true},"execution_count":null,"outputs":[]}]}